---
title: "plyranges: a grammar for transforming genomics data" 
author:
  - name: Stuart Lee
    email: stuart.lee1@monash.edu
    affiliation: Monash University
  - name: Michael Lawrence
    email: michael.lawrence@gene.com
    affiliation: Genentech
  - name: Di Cook
    email: di.cook@monash.edu
    affiliation: Monash University
address:
  - code: Monash University
    address: Department of Econometrics and Business Statistics, Clayton, Victoria, Australia
  - code: Genentech
    address: Bioinformatics and Computational Biology, Genentech, Inc., South San Francisco, California, United States of America 
abstract: |
    The Bioconductor project has created many useful data abstractions for analysing high-throughput genomics experiments. However, there is a cognitive load placed on a user in learning a data abstraction and understanding its appropriate use. Throughout a standard workflow, a user must navigate and know many of these abstractions to perform an genomic analysis task, when a single data abstraction, a GRanges object will suffice. The GRanges class naturally represent genomic intervals and their associated measurements. By recognising that the GRanges class follows 'tidy' data principles we have created a grammar of genomic data transformation. The grammar defines verbs for performing actions on and between genomic interval data. It provides a principled way
    of performing common genomic data analysis tasks through a coherent interface to existing Bioconductor infrastructure, resulting in human readable analysis workflows. We have implemented this grammar as an Bioconductor/R package called plyranges.
  
bibliography: references.bib
output: 
  rticles::plos_article:
csl: plos.csl
---
```{r setup, include = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, comment = "#>", 
                      fig.width = 5, fig.height = 3, fig.align = "center")
options(digits = 2)
library(ggbio)
library(ggplot2)
library(plyranges)

library(AnnotationHub)
q <- AnnotationHub()
bw_file <- q[["AH33458"]] 
```
# Introduction

High-throughput genomics promises to unlock new disease therapies,
and strengthen our knowledge of basic biology. To deliver on those promises, 
scientists must derive a stream of knowledge from a deluge of data. Genomic 
data is challenging in both scale and complexity. Innovations in sequencing 
technology often outstrip our capacity to process the output. Beyond their common
association with genomic coordinates, genomic data are heterogeneous,
consisting of raw sequence read alignments, genomic feature
annotations like genes and exons, and summaries like coverage vectors,
ChIP-seq peak calls, variant calls, and per-feature read
counts. Genomic scientists need software tools to wrangle the
different types of data, process the data at scale, test hypotheses,
and generate new ones, all while focusing on the biology, not the
computation. For the tool developer, the challenge is to define ways
to model and operate on the data that align with the mental model of
scientists, and to provide an implementation that scales with their
ambition.

Several domain specific languages (DSLs) enable scientists to process and reason
about heterogenous genomics data heterogenous genomics data by expresssing common
operations, such as range manipulation and overlap-based joins, using
the vocabulary of genomics. Their implementations either delegate
computations to a database, or operate over collections of files in
standard formats like BED.An example of the former is the Genome Query 
Language (GQL) and its distributed implementation GenAp which use an 
SQL-like syntax for fast retrieval of information of unprocessed 
sequencing data @Kozanitis2014-va; @Kozanitis2016-bm. Similarly, the Genometric 
Query Language (GMQL) implements a relational algebra for combining genomic datasets 
@Kaitoua2017-pw.  The command line application BEDtools develops an extensive 
algebra for performing arithmetic between two or more sets of genomic regions 
@Quinlan2010-gc. All of the aformentioned DSLs are designed to be evaluated
either at the commandline or embedded in scripts for batch processing. They 
exist in asparse ecosystem, mostly consisting of UNIX and database tools that
lack biological semantics and operate at the level of files and
database tables.

The Bioconductor/R packages `IRanges` and `GenomicRanges` 
[@r-core; @Lawrence2013-wg; @Huber2015-ei] define a DSL for 
analysing genomics data with R, an interactive data analysis environment that 
encouragesreproducibility and provides high-level abstractions for manipulating,
modeling and plotting data, through state of the art methods in
statistical computing. The packages define object-oriented (OO)
abstractions for representing genomic data and enable
interoperability by allowing users and developers to use these
abstractions in their own code and packages. Other genomic DSLs 
that are embedded in programming languages include pybedtools and valr 
[@Dale2011-js; @Kent2017], however these packages lack the interoperability
provided by in the aformentioned Bioconductor packages and are not easily 
extended.

The Bioconductor infrastructure models the genomic data and operations from the
perspective of the power user, one who understands and wants to take
advantage of the subtle differences in data types. This design has
enabled the development of sophisticated tools, as evidenced by the
hundreds of packages depending the framework. Unfortunately, the
myriad of data structures have overlapping purposes and important but
obscure differences in behavior that often confuse the typical end
user.

Recently, there has been a concerted, community effort to standardize
R data structures and workflows around the notion of tidy data
@Wickham2014-jc. A tidy dataset is defined to be to a tabular
data structure that has observations as rows and columns as variables, and each
tidy dataset represents measurements from a single observational unit.
The tidy data pattern is useful because it allows 
us to see how the data relates to the design of an experiment
and the variables measured. The `dplyr` pacakge [@Wickham2017-dplyr] 
defines an API that maps notions from the general relational algebra to 
operations on tidy data. It expresses each operation as a cohesive, endomorphic
verb. Taken together these features enable a user to write human
readable analysis workflows.

We have created a genomic DSL called `plyranges` that reformulates
notions from existing genomic algebras and embeds them in R as a
genomic extension of `dplyr`. By analogy, `plyranges` is to the
genomic algebra, as `dplyr` is to the relational algebra.  The
`plyranges` Bioconductor package implements the language on top of a
key subset of Bioconductor data structures and thus fully integrates
with the Bioconductor framework, gaining access to its scalable data
representations and sophisticated statistical methods.


# Design and Implementation

The `plyranges` DSL is built on the most general Bioconductor data structure, 
GRanges, which is capable of
representing all types of genomic data at a semantic level that
roughly matches the intuition of most users.  A GRanges is essentially
a table, with columns for the chromosome, start and end coordinates,
and the strand, along with an arbitrary set of additional columns,
consisting of measurements or metadata specific to the data type or
experiment. For example a GRanges can be used to represent a gene with
its chromosomal coordinates, and along with its exon identifiers; or 
a GRanges can represent an RNA-seq experiment as a set of genes
with a corresponding count column.

By definition the GRanges follow  the tidy data pattern: it is a rectangular 
table corresponding to a single biological context. Each row contains a
single observation and each column is a variable about that
observation. Hence, we have designed the `plyranges` DSL to extend the grammar
and design principles of `dplyr`:  cohesion, consistency, endomorphism,
and fluency. All of these principles are defined and discussed
below in the context of the GRanges class. Where applicable we contrast our 
design to the existing Bioconductor infrastructure.


## Cohesion

A function is cohesive if it performs a singular task and does not produce
any side-effects. In the `plyranges` DSL our algebra for performing
genomic arithmetic is a key example of cohesion. We define anchoring operators
that decorate a GRanges object with an 'anchor' and modify the semantics
of performing genomic arithmetic. The anchoring operators amount to fixing a GRanges
object by its start, center, or end coordinates (or fixing these coordinates
by strand). This enables any arithmetic function that performs a 
coordinate transformation to remain cohesive: that is they always perfom
the same operation regardless of whether a GRanges object is anchored or not.
The only difference is the result of performing the arithimetic changes when
contextual information is added to the GRanges object. 

Another example of our algebra altering object semantics, while maintaining 
cohesion is through the 'group_by' operator. Like anchoring, this operator 
decorates a GRanges object with a column name (or names) that defines a 
partitioning of the  GRanges by the unique values in the column(s). Functions 
defined in the  `plyranges` DSL that perform restriction, aggregation, or 
column modfication still perform those singular tasks, however grouping changes
how those tasks are performed. 

Our algebra recasts the actions of finding overlaps or nearest neightbours 
between two genomic regions as a relational join operator. The join operator 
acts on two GRanges object, a query and a subject. The join operator is 
relational in the sense that metadata from the query and subject ranges is 
retained in the joined range.  The commonality between
all join operators in the `plyranges` DSL is to use the index of where in
the query range the subject range 'hits' the query range as a primary key 
(figure *need to make figure*). The notion of 'hits' and hence
the resulting key is determined by the type of join (preceding, nearest, follows
overlaps). 

We extend this idea by introducing three types of overlap joins: inner,
intersect and left. The inner join considers a hit to be any overlap between
subject and query and expands the query range to have length equal to the 
number of hits. The intersect join uses the same definition of a hit as
the inner join but returns a range where the start and end coordinates
are the intersect of coordinates in the subject that hit the query. Finally,
the overlap left join is akin to left outer join in Cobb's relational algebra:
it performs an overlap inner join but also returns all query ranges that
are not hit by the subject.

The behaviour of a join operator can be further altered with additional
suffixes by restricting or expanding how a subject 'hits' a query. For example,
for overlap joins we can use suffixes to encapsulate Allan's Interval Algebra:
to consider subject 'hits' that are entirely 'within' a query range, the 'within'
prefix is used. We also use the 'directed' suffix to explicitly include 
notions of strandedness in our algebra. 

comparsion to Bioconductor API here? table of join ops?

```{r olap, echo = FALSE, fig.cap="The three overlap joins: the query and subject ranges are coloured by their metadata. When an overlap is performed the resulting range is filled by the query metadata and the metadata from the subject colours the outside of the range.", fig.width = 5, fig.height = 7}
a <- GRanges(seqnames = "chr1",
               strand = c("+", "-"),
               ranges = IRanges(c(1, 9), c(7, 10)),
               key.a = letters[1:2])

b <- GRanges(seqnames = "chr1",
               strand = c("-", "+"),
               ranges = IRanges(c(2, 6), c(4, 8)),
               key.b = LETTERS[1:2])

c <- join_overlap_intersect(a,b)
d <- join_overlap_inner(a, b)
e <- join_overlap_left(a, b)

p1 <- autoplot(a, aes(fill = key.a)) + 
  scale_fill_brewer(type = "qual", palette = "Set2") + 
  guides(fill = FALSE)
p2 <- autoplot(b, aes(fill = key.b))  + 
  scale_fill_brewer(type = "qual", palette = "Set1") +
  guides(fill = FALSE)
p3 <- autoplot(c, aes(fill = key.a, colour = key.b)) + 
  scale_fill_brewer(type = "qual", palette = "Set2") +
  scale_color_brewer(type = "qual", palette = "Set1") +
  guides(fill = FALSE, color = FALSE) 
p4 <- autoplot(d, aes(fill = key.a, colour = key.b)) + 
  scale_fill_brewer(type = "qual", palette = "Set2") +
  scale_color_brewer(type = "qual", palette = "Set1") +
  guides(fill = FALSE, colour = FALSE)
p5 <- autoplot(e, aes(fill = key.a, colour = key.b))  +
  scale_fill_brewer(type = "qual", palette = "Set2") +
  scale_color_brewer(type = "qual", palette = "Set1") +
  guides(fill = FALSE, colour = FALSE)

tracks(query = p1, subject = p2, 
       `intersect` = p3, 
       `inner` = p4, 
       `left` = p5) 
```

 
## Consistency 

The methods `as_granges()` and `as_iranges()`
for constructing GRanges from tabular data structures, such as the _data.frame_ in
base R. These methods use non-standard evaluation so columns in a _data.frame_
can be modified before a GRanges object is created. The API also has
convenience methods for annotating or extracting annotations from _GRanges_
objects with the `set_genome_info()` and `get_genome_info()` functions.

There is a consistent framework for reading and writing 
files from and to common genomic data formats, using the _rtracklayer_ package
as a back-end @Lawrence2009-nt. The methods are implemented in the `read_/write_` family of 
functions, currently _plyranges_ can read and write BAM, BED, BEDPE, 
narrowPeaks, GFF/GTF, WIG and BigWig files. 

## Endomorphism

This is possible because every 
function call is an endomorphism: when the input is GRanges object the output
will also be a GRanges object. One advantage of endomorphism is that it 
does not  require any additional learning of classes beyond GRanges and 
the _DataFrame_ classes. This strongly deviates from the design of 
the GRanges Bioconductor packages, where many methods return a new class
upon return. The Bioconductor design enables efficient computing as users
are exposed to low-level features of its API which _plyranges_ abstracts
away.

The combination of verbs we have defined above cover most operations that
can be performed in the original _IRanges_ and _GenomicRanges_ packages
without the user being exposed to new classes. In those packages to perform
most operations requires users to learn many classes and perform 
additional manipulations to return the results of their computation back to a
GRanges object.

## Fluency 

Using the design principles defined above every function in `plyranges`
performs a single action on GRanges objects. The `plyranges` DSL implments the 
core verbs from the `dplyr` package and implements a genomic relational algebra
for transforming GRanges objects (table x, y). Each verb preserves the 
semantics of GRanges object and works with derivatives of the GRanges class. 
Both of these aspects reduce the cognitive load on a new user since most 
manipulations can be performed with a vocabulary of several verbs, rather 
than having to memorise function names that are nouns. 

This approach strongly constrasts the `GenomicRanges/IRanges` OO interface, 
which emphasises the use of setter and getter methods. In that interface, 
core components and metadata are updated via replacement methods 
(requiring knowledge of the class components), while our interface requires 
only a single call to `mutate()` to perform the modification. 

Workflows can be composed by chaining verbs together into 'sentences' via the 
forward pipe operator,`%>%`  (exported from the R package `magrittr` 
@R-magrittr), which can be read as the word 'then'. Overall, this allows users 
to write human readable code because workflows describe what the code is doing 
rather than how its doing it.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
library(tibble)
feature_tbl <- tribble(
  ~Verb, ~Action, ~Description,
  "`mutate()`", "modifies columns", "Takes a GRanges object and a set of name-value pairs and generates a new GRanges object that with modified or new metadata columns or modified core components (start, end, width, seqnames, strand).",
 "`filter()`", "subset rows", "Takes a GRanges object and a set of logical expressions and restricts the GRanges object to where all logical expressions are true.",
 "`summarise()`", "aggregate one or more columns by a function", "Takes a GRanges object and a set of name-value pairs and aggregates the GRanges according to functions evaluated in the name-value pairs.",
"`group_by()`", "partition a GRanges object by a column", "Create an implicit grouping of GRanges object by one or more columns. This modifies the actions of verbs, so they are performed on each partition created by the grouping.",
"`select()`", "select columns of a GRanges objects", "Drop or reorder metadata columns.",
"`arrange()`", "sort a GRanges object by columns", "Sort a GRanges object by named variables",
"`disjoin_ranges()`", "aggregate one more columns of a GRanges object over the union of end coordinates", "Takes a GRanges object and a set of name-value pairs and expands the GRanges object by taking the union of end coordinates. For each row that was included to form the final union, the aggregation function defined by a name-value pair is called.",
"`reduce_ranges()`", "aggregate one more columns of a GRanges object by merging overlapping and neighbouring ranges.", "Takes a GRanges object and a set of name-value pairs and reduces the GRanges object by merging overlapping and neighouring ranges. For each row that was included to form merged range, the aggregation function defined by a name-value pair is called."
)
```

## Limitations

A caveat to constructing a compatible API with `dplyr` is that 
`plyranges` makes extensive use of non-standard evaluation in R
(achieved via the `rlang` package @R-rlang). Simply, this
means that computations are performed and evaluated in the context of the 
GRanges objects, which emphasises the interactive nature of the API. This has
the disadvantage that programming with `plyranges` becomes more difficult 
because a user needs to know about non-standard evaluation and user defined
functions can be difficult to debug.

Method chaining via the pipe operator can also be difficult to debug,
as there multiple points of failure

# Results 

Here we provide examples on how to use the `plyranges` DSL to construct
genomic data workflows.

## Peak Finding

We use the Bioconductor package _AnnotationHub_ @R-ahub to search for 
BigWig files from ChIP-Seq experiments from the Human Epigenome Roadmap project 
@Roadmap_Epigenomics_Consortium2015-pr. We choose to focus on assays for primary
T CD8+ memory cells from peripheral blood. We can then read the BigWig file 
corresponding to the H3 lysine 27 trimethylation (H3K27Me3) methylation mark 
over chromosome 10. 

First, we gather the BigWig file and extract its annotation information and 
filter it to chromosome 10.

```{r load-bw, cache = TRUE}
library(plyranges)
chr10_ranges <- bw_file %>% 
  get_genome_info() %>%
  filter(seqnames == "chr10")
```

Then we read the BigWig file only extracting scores if they overlap chromosome
10. The annotation information from the file is automatically included (in this
case the hg19 genome build).

```{r}
chr10_scores <- bw_file %>%
  read_bigwig(overlap_ranges = chr10_ranges) %>%
  set_genome_info(genome = "hg19")
chr10_scores
```

The `reduce_ranges()` operation is used to find coverage peaks 
across chromosome 10. We can manually set a threshold to restrict genomic
regions to have a coverage score of greater than 8, and
then merge nearby regions. The maximum coverage is computed over all the
coverage scores in the regions that were reduced. 

```{r}
all_peaks <- chr10_scores %>% 
  filter(score > 8) %>% 
  reduce_ranges(score = max(score))
```

Returning to the GRanges object containing normalised coverage scores for
the methylation data, we can filter to find the coordinates of the peak 
containing the maximum coverage score. We can then find 
a 5000 nt region centered around the maximum position by anchoring and 
modifying the the width. 

```{r max-score-region}
chr10_max_score_region <- chr10_scores %>%
  filter(score == max(score)) %>% 
  anchor_center() %>%
  set_width(5000)
```

Finally, the overlap inner join is used to restrict the chromosome 10
normalised coverage scores that are within the 5000nt region that contain
the max peak on chromosome 10 (visualised in figure \ref{fig:peak-viz}).

```{r peak_region}
peak_region <- chr10_scores %>%
  join_overlap_inner(chr10_max_score_region)

```

```{r peak-viz, echo = FALSE, fig.cap = "Visualisation of normalised coverage scores accross a 5000nt region of chromosome 10 from H3K27Me3 ChIP-Seq assay from the Human Epigenome Roadmap project."}
ggbio::autoplot(peak_region, 
                aes(y = score.x), 
                geom = "blank") + 
  geom_area(aes(x = start))
```


## Computing Windowed Statistics

(example of group_by_overlaps + summarise)

## Transition Transversion Ratio

(example of group_by + mutate + summarise and working on an object that inherits
from GRanges)

# Availablilty and Future Work

The _plyranges_ package is available on the Bioconductor project website 
[https://bioconductor.org](https://bioconductor.org) or can be accessed
via Github [https://github.com/sa-lee/plyranges](https://github.com/sa-lee/plyranges).
We aim to continue developing the `plyranges` package and extend it for use
with more complex data structures  such as the 
_SummarizedExperiment_ class, which can be used for analysing transcriptomic
and variant data. As the `plyranges` interface encourages tidy data 
practices it integrates well with the principles of the grammar of graphics, 
we aim to use it to prepare data for the visualisation of multimodal biological 
datasets.

# References {#references .unnumbered}
