---
title: "plyranges: a grammar for transforming genomics data" 
author:
  - name: Stuart Lee
    email: stuart.lee1@monash.edu
    affiliation: Monash University
  - name: Michael Lawrence
    email: michael.lawrence@gene.com
    affiliation: Genentech
  - name: Di Cook
    email: di.cook@monash.edu
    affiliation: Monash University
address:
  - code: Monash University
    address: Department of Econometrics and Business Statistics, Clayton, Victoria, Australia
  - code: Genentech
    address: Bioinformatics and Computational Biology, Genentech, Inc., South San Francisco, California, United States of America 
abstract: |
    The Bioconductor project has created many useful data abstractions for analysing high-throughput genomics experiments. However, there is a cognitive load placed on a user in learning a data abstraction and understanding its appropriate use. Throughout a standard workflow, a user must navigate and know many of these abstractions to perform an genomic analysis task, when a single data abstraction, a _Ranges_ object will suffice. The _Ranges_ class naturally represent genomic intervals and their associated measurements. By recognising that the _Ranges_ class follows 'tidy' data principles we have created a grammar of genomic data transformation. The grammar defines verbs for performing actions on and between genomic interval data. It provides a principled way
    of performing common genomic data analysis tasks through a coherent interface to existing Bioconductor infrastructure, resulting in human readable analysis workflows. We have implemented this grammar as an Bioconductor/R package called plyranges.
  
bibliography: references.bib
output: 
  rticles::plos_article:
csl: plos.csl
---
```{r setup, include = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, comment = "#>", 
                      fig.width = 5, fig.height = 3, fig.align = "center")
options(digits = 2)
library(ggbio)
library(ggplot2)
library(plyranges)

library(AnnotationHub)
q <- AnnotationHub()
bw_file <- q[["AH33458"]] 
```
# Introduction

High-throughput genomics promises to unlock new disease therapies,
reveal basic biology, and solve other problems that plague the human
condition. To deliver on those promises, scientists must derive a
stream of knowledge from a deluge of data. Genomic data is challenging
in both scale and complexity. Innovations in sequencing technology
often outstrip our capacity to process the output. Beyond their common
association with genomic coordinates, genomic data are heterogeneous,
consisting of raw sequence read alignments, genomic feature
annotations like genes and exons, and summaries like coverage vectors,
ChIP-seq peak calls, variant calls, and per-feature read
counts. Genomic scientists need software tools to wrangle the
different types of data, process the data at scale, test hypotheses,
and generate new ones, all while focusing on the biology, not the
computation. For the tool developer, the challenge is to define ways
to model and operate on the data that align with the mental model of
scientists, and to provide an implementation that scales with their
ambition.

Several domain specific languages (DSLs) enable scientists to process
and reason about heterogenous genomics data by expresssing common
operations, such as range manipulation and overlap-based joins, using
the vocabulary of genomics. Their implementations either delegate
computations to a database, or operate over collections of files in
standard formats like BED.  An example of the former is the Genome
Query Language (GQL) and its distributed implementation GenAp which
use an SQL-like syntax for fast retrieval of information of
unprocessed sequencing data @Kozanitis2014-va; @Kozanitis2016-bm.
Similarly, the Genometric Query Language (GMQL) implements a
relational algebra for combining genomic datasets @Kaitoua2017-pw. The
command line application BEDtools defines an extensive algebra for
performing arithmetic between two or more sets of genomic regions
stored as files @Quinlan2010-gc; @Dale2011-js. All of the
aformentioned DSLs are designed to be evaluated either at the command
line or embedded in scripts for batch processing. They exist in a
sparse ecosystem, mostly consisting of UNIX and database tools that
lack biological semantics and operate at the level of files and
database tables.

The Bioconductor packages `IRanges` and `GenomicRanges`
(@Lawrence2013-wg; @Huber2015-ei) define a DSL for analysing genomics
data with R, an interactive data analysis environment that encourages
reproducibility and provides high-level abstractions for manipulating,
modeling and plotting data, through state of the art methods in
statistical computing. The packages define object-oriented (OO)
abstractions for representing genomic data and enable
interoperability by allowing users and developers to use these
abstractions in their own code and packages. The Bioconductor
infrastructure models the genomic data and operations from the
perspective of the power user, one who understands and wants to take
advantage of the subtle differences in data types. This design has
enabled the development of sophisticated tools, as evidenced by the
hundreds of packages depending the framework. Unfortunately, the
myriad of data structures have overlapping purposes and important but
obscure differences in behavior that often confuse the typical end
user.

Recently, there has been a concerted, community effort to standardize
R data structures and workflows around the notion of tidy data
@Wickham2014-jc. A tidy dataset is defined to have a tabular structure
that has observations as rows and columns as variables. Each tidy
dataset represents measurements from a single observational unit.  The
tidy data pattern is useful because it allows us to see how the data
relates to the design of an experiment and the variables measured.
The `dplyr` pacakge [@Wickham2017-dplyr] defines an API that maps
notions from the general relational algebra to operations on tidy
data. It expresses each operation as a cohesive, endomorphic
verb. Taken together these features enable a user to write human
readable analysis workflows.

We have created a genomic DSL called `plyranges` that reformulates
notions from existing genomic algebras and embeds them in R as a
genomic extension of `dplyr`. By analogy, `plyranges` is to the
genomic algebra, as `dplyr` is to the relational algebra.  The
`plyranges` Bioconductor package implements the language on top of a
key subset of Bioconductor data structures and thus fully integrates
with the Bioconductor framework, gaining access to its scalable data
representations and sophisticated statistical methods.

# Stuff pushed out of the intro (needs a home)

The most general Bioconductor data structure, GRanges, is capable of
representing all types of genomic data at a semantic level that
roughly matches the intuition of most users.  A GRanges is essentially
a table, with columns for the chromosome, stand and end coordinates,
and the strand, along with an arbitrary set of additional columns,
consisting of measurements or metadata specific to the data type or
experiment.  For example, a gene can be represented by its chromosomal
coordinates, along with its identifier and the identifiers of its
exons; or an RNA-seq experiment may be represented as sets of genes
with a matching count column.

GRanges follows the tidy data pattern: it is a rectangular table
corresponding to a single biological context. Each row contains a
single observation and each column is a variable about that
observation.

Cohesion means that each function performs a singular task and has no
side-effects, while endomorphism means a function call returns the
same type of object as its input.

# Design and Implementation

The `plyranges` DSL is built on two fundamental data structures defined
by the `IRanges` and `GenomicRanges` packages called _IntegerRanges_
and _GenomicRanges_. Unless otherwise specified, throughout the paper
we refer to either of these data structures as _Ranges_. In its simplest form 
the data model for an _IntegerRanges_ object is defined as a table with
$n$ rows, where each row contains a closed interval of two integers:

$$
\textit{IntegerRange} := \{ \left[\text{start}_i, \text{end}_{i}\right]  : i = 1\dots n \}.
$$
In this form an _IntegerRanges_ object has three core columns: a start, an
end, and the width of the interval. The _GenomicRanges_ data
model has additional semantics providing biological context, strand and 
sequence name (seqname), as well as containing an _IntegerRanges_ object.

$$
\textit{GenomicRange} := \{  \{\text{seqname}_i, \left[\text{start}_i, \text{end}_{i}\right] , \text{strand}_i\}  : i = 1\dots n \}.
$$
A _GenomicRanges_ object can have an additional property that provides
annotation for each sequence name over a genome. This contstrains the the 
start and end points for a given sequence to lie inside the bounds
of the genome space. Also note that _GenomicRanges_ have one-based 
coordinates rather than zero-based coordinates.  Additional measurements
or annotations can be bound to the bare _IntegerRanges_ or _GenomicRanges_ to
form metadata columns.

By definition the _Ranges_ class encapsulate tidy data prinicples because
every row corresponds to a sequence and every column corresponds to a variable.
Hence, we have designed the `plyranges` DSL to have the grammar
and design principles of `dplyr`: fluency, consistency, cohesion and 
endomorphism. All of these principles are discussed with respect to the 
_Ranges_ data model below. Where possible we contrast our design to the existing
Bioconductor infrastructure.

A caveat to constructing a compatible API with `dplyr` is that 
`plyranges` makes extensive use of non-standard evaluation in R
(achieved via the `rlang` package @R-rlang). Simply, this
means that computations are performed and evaluated in the context of the 
_Ranges_ objects, which emphasises the interactive nature of the API. This has
the disadvantage that programming with `plyranges` becomes more difficult 
because a user needs to know about non-standard evaluation and user defined
functions can be difficult to debug.


## Fluency 

We have designed every function to perform a single
action on a _Ranges_ object. The `plyranges` DSL implments the core verbs from the `dplyr` package
and implements context specific verbs for transforming _Ranges_ objects (described in
table ). Each verb preserves the semantics of _Ranges_ object and via
duck typing works with derivatives of the _Ranges_ class. 
Both of these aspects reduce the cognitive load on a new user since most 
manipulations can be performed with a  vocabulary of several verbs, rather 
than having to memorise function names that are nouns. Moreover, this approach 
strongly constrasts the `GenomicRanges/IRanges` OO interface, which emphasises 
the use of setter and getter methods. In that interface, core components and 
metadata are updated via replacement methods (requiring knowledge of the
class components), while our interface requires only a single call to `mutate()`
to perform the modification. 

Workflows can be composed by chaining verbs together into 'sentences' via the 
forward pipe operator,`%>%`  (exported from the R package `magrittr` 
@R-magrittr), which can be read as the word 'then'. Overall, this  allows users 
to write human readable code because workflows describe what the code is doing 
rather than how its doing it.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
library(tibble)
feature_tbl <- tribble(
  ~Verb, ~Action, ~Description,
  "`mutate()`", "modifies columns", "Takes a _Ranges_ object and a set of name-value pairs and generates a new _Ranges_ object that with modified or new metadata columns or modified core components (start, end, width, seqnames, strand).",
 "`filter()`", "subset rows", "Takes a _Ranges_ object and a set of logical expressions and restricts the _Ranges_ object to where all logical expressions are true.",
 "`summarise()`", "aggregate one or more columns by a function", "Takes a _Ranges_ object and a set of name-value pairs and aggregates the _Ranges_ according to functions evaluated in the name-value pairs.",
"`group_by()`", "partition a _Ranges_ object by a column", "Create an implicit grouping of _Ranges_ object by one or more columns. This modifies the actions of verbs, so they are performed on each partition created by the grouping.",
"`select()`", "select columns of a _Ranges_ objects", "Drop or reorder metadata columns.",
"`arrange()`", "sort a _Ranges_ object by columns", "Sort a _Ranges_ object by named variables",
"`disjoin_ranges()`", "aggregate one more columns of a _Ranges_ object over the union of end coordinates", "Takes a _Ranges_ object and a set of name-value pairs and expands the _Ranges_ object by taking the union of end coordinates. For each row that was included to form the final union, the aggregation function defined by a name-value pair is called.",
"`reduce_ranges()`", "aggregate one more columns of a _Ranges_ object by merging overlapping and neighbouring ranges.", "Takes a _Ranges_ object and a set of name-value pairs and reduces the _Ranges_ object by merging overlapping and neighouring ranges. For each row that was included to form merged range, the aggregation function defined by a name-value pair is called."
)
```

 

## Consistency 

The _plyranges_ API has an expressive algebra for performing arithmetic on Ranges via
the verbs `set_width()` and `stretch()`. As the names suggest `set_width()`
modifies the width of a Ranges object, while `stretch` extends the start and
end of a Ranges object. These can be chained with the anchoring functions
`anchor_start()`, `anchor_end()`, `anchor_center()`, `anchor_3p()` or 
`anchor_5p()`, which fix the coordinates of a Ranges object in place. 
Moreover, the `shift_` and `flank_` family of functions can be used to shift
all coordinates in a Ranges object or generate flanking regions from a Ranges 
object to the left, right, upstream or downstream of the input. Unlike, the
Bioconductor API, _plyranges_ makes it explicit via function calls whether to
take into account the strand information of a _Ranges_ object.


The methods `as_granges()` and `as_iranges()`
for constructing _Ranges_ from tabular data structures, such as the _data.frame_ in
base R. These methods use non-standard evaluation so columns in a _data.frame_
can be modified before a _Ranges_ object is created. The API also has
convenience methods for annotating or extracting annotations from _GRanges_
objects with the `set_genome_info()` and `get_genome_info()` functions.

There is a consistent framework for reading and writing 
files from and to common genomic data formats, using the _rtracklayer_ package
as a back-end @Lawrence2009-nt. The methods are implemented in the `read_/write_` family of 
functions, currently _plyranges_ can read and write BAM, BED, BEDPE, 
narrowPeaks, GFF/GTF, WIG and BigWig files. 

## Endomorphism

 (that
are named as nouns) with many arguments (which is required in the existing 
Bioconductor packages)
 This is possible because every 
function call is an endomorphism: when the input is _Ranges_ object the output
will also be a _Ranges_ object. One advantage of endomorphism is that it 
does not  require any additional learning of classes beyond _Ranges_ and 
the _DataFrame_ classes. This strongly deviates from the design of 
the _Ranges_ Bioconductor packages, where many methods return a new class
upon return. The Bioconductor design enables efficient computing as users
are exposed to low-level features of its API which _plyranges_ abstracts
away. Method chaining via the pipe operator can also be difficult to debug,
as there multiple points of failure.

The combination of verbs we have defined above cover most operations that
can be performed in the original _IRanges_ and _GenomicRanges_ packages
without the user being exposed to new classes. In those packages to perform
most operations requires users to learn many classes and perform 
additional manipulations to return the results of their computation back to a
_Ranges_ object.


## Cohesion


## Overlapping Ranges

A common operation to perform between two _Ranges_ objects is to find overlaps
or nearest neighbours. The _plyranges_ API recasts these operations as 'joins'
or 'pairing' operations. For overlaps, there are three join operations: 
`join_overlap_intersect()`, `join_overlap_inner()` and `join_overlap_left()`
which are shown in figure (\ref{fig:olap}). 

```{r olap, echo = FALSE, fig.cap="The three overlap joins: the query and subject ranges are coloured by their metadata. When an overlap is performed the resulting range is filled by the query metadata and the metadata from the subject colours the outside of the range.", fig.width = 5, fig.height = 7}
a <- GRanges(seqnames = "chr1",
               strand = c("+", "-"),
               ranges = IRanges(c(1, 9), c(7, 10)),
               key.a = letters[1:2])

b <- GRanges(seqnames = "chr1",
               strand = c("-", "+"),
               ranges = IRanges(c(2, 6), c(4, 8)),
               key.b = LETTERS[1:2])

c <- join_overlap_intersect(a,b)
d <- join_overlap_inner(a, b)
e <- join_overlap_left(a, b)

p1 <- autoplot(a, aes(fill = key.a)) + 
  scale_fill_brewer(type = "qual", palette = "Set2") + 
  guides(fill = FALSE)
p2 <- autoplot(b, aes(fill = key.b))  + 
  scale_fill_brewer(type = "qual", palette = "Set1") +
  guides(fill = FALSE)
p3 <- autoplot(c, aes(fill = key.a, colour = key.b)) + 
  scale_fill_brewer(type = "qual", palette = "Set2") +
  scale_color_brewer(type = "qual", palette = "Set1") +
  guides(fill = FALSE, color = FALSE) 
p4 <- autoplot(d, aes(fill = key.a, colour = key.b)) + 
  scale_fill_brewer(type = "qual", palette = "Set2") +
  scale_color_brewer(type = "qual", palette = "Set1") +
  guides(fill = FALSE, colour = FALSE)
p5 <- autoplot(e, aes(fill = key.a, colour = key.b))  +
  scale_fill_brewer(type = "qual", palette = "Set2") +
  scale_color_brewer(type = "qual", palette = "Set1") +
  guides(fill = FALSE, colour = FALSE)

tracks(query = p1, subject = p2, 
       `intersect` = p3, 
       `inner` = p4, 
       `left` = p5) 
```

These operations consider any overlap between
two input ranges and return any corresponding metadata from both Ranges objects
as metadata. The intersect join takes the intersect of the start and end coordinates
of overlapping intervals of the query and subject _Ranges_ 
(for _GenomicRanges_ it also accounts for sequence name), when there is a overlap
the metadata corresponding to the query and subject _Ranges_ are returned. 
Similarly, inner join takes the start and end coordinates of the query _Ranges_
that overlap the subject _Ranges_ and returns metadata of the overlapping query
and subject _Ranges_. Finally, the left join performs a left outer join between
the query and subject _Ranges_, it returns all genomic intervals from the query
ranges, and returns missing values in metadata columns when there is no overlap.

A user may also restrict or group by overlaps with the `filter_by_overlaps()`,
`filter_by_non_overlaps()` and `group_by_overlaps()`. All overlap methods can
be modified with the `within` suffix (which changes the type of overlap 
from 'any' to 'within') or the `directed` suffix (which takes into account
the strand of a _GenomicRanges_ object.). 

For nearest neighbours, the _plyranges_ API provides `join_nearest()`, 
`join_precede()`, and `join_follow()` functions. These functions are similar
to the overlapping functions, in that they return the query ranges that are
nearest (or precede or follow) the subject ranges and add metadata from
the subject ranges when the query is a nearest neighbour of the subject. Like
the overlap joins, these functions can modified with suffixes to find nearest
neighbours that are left, right, upstream or downstream of the subject.

The pairing operations, `pair_overlap()`, `pair_nearest()`, `pair_follow()`, 
and `pair_precede()` are similar to the join operation but instead of returning
a _Ranges_, they pair up the subject and query _Ranges_ objects into a _DataFrame_,
alongside their metadata columns. This data structure is similar to the _Pairs_
data structure in the _S4Vectors_ @R-S4vectors package or the BED-PE file format. 



# Results 

As an example, we use the Bioconductor package _AnnotationHub_ @R-ahub to search for 
BigWig files from ChIP-Seq experiments from the Human Epigenome Roadmap project @Roadmap_Epigenomics_Consortium2015-pr.
We choose to focus on assays for primary T CD8+ memory cells from peripheral 
blood. We can then read the BigWig file  corresponding to the H3 lysine 27 
 trimethylation (H3K27Me3) 
methylation mark over chromosome 10. 

First, we gather the BigWig file
and extract its annotation information and filter it to chromosome 10.

```{r load-bw, cache = TRUE}
library(plyranges)
chr10_ranges <- bw_file %>% 
  get_genome_info() %>%
  filter(seqnames == "chr10")
```

Then we read the BigWig file only extracting scores if they overlap chromosome
10. The annotation information from the file is automatically included (in this
case the hg19 genome build).

```{r}
chr10_scores <- bw_file %>%
  read_bigwig(overlap_ranges = chr10_ranges) %>%
  set_genome_info(genome = "hg19")
chr10_scores
```

The `reduce_ranges()` operation is used to find coverage peaks 
across chromosome 10. We can manually set a threshold to restrict genomic
regions to have a coverage score of greater than 8, and
then merge nearby regions. The maximum coverage is computed over all the
coverage scores in regions that were reduced. 

```{r}
all_peaks <- chr10_scores %>% 
  filter(score > 8) %>% 
  reduce_ranges(score = max(score))
```

Returning to the _Ranges_ object containing normalised coverage scores for
the methylation data, we can filter to find the coordinates of the peak 
containing maximum coverage score. We can then find 
a 5000 nt region centered around the maximum position by anchoring and 
modifying the the width. 

```{r max-score-region}
chr10_max_score_region <- chr10_scores %>%
  filter(score == max(score)) %>% 
  anchor_center() %>%
  set_width(5000)
```

Finally, the overlap inner join could be used to restrict the chromosome 10
normalised coverage scores that are within the 5000nt region that contains
the max peak on chromosome 10 (visualised in figure \ref{fig:peak-viz}).

```{r peak_region}
peak_region <- chr10_scores %>%
  join_overlap_inner(chr10_max_score_region %>% 
                       select(-score))

```

```{r peak-viz, echo = FALSE, fig.cap = "Visualisation of normalised coverage scores accross a 5000nt region of chromosome 10 from H3K27Me3 ChIP-Seq assay from the Human Epigenome Roadmap project."}
ggbio::autoplot(peak_region, 
                aes(y = score), 
                geom = "blank") + 
  geom_area(aes(x = start))
```


# Availablilty and Future Work

The _plyranges_ package is available on the Bioconductor project website 
[https://bioconductor.org](https://bioconductor.org) or can be accessed
via Github [https://github.com/sa-lee/plyranges](https://github.com/sa-lee/plyranges).
We aim to continue developing the `plyranges` package and extend it for use
with more complex data structures  such as the 
_SummarizedExperiment_ class, which can be used for analysing transcriptomic
and variant data. As the `plyranges` interface encourages tidy data 
practices it integrates well with the principles of the grammar of graphics, 
we aim to use it to prepare data for the visualisation of multimodal biological 
datasets.

# References {#references .unnumbered}
