---
title: "plyranges: a grammar for transforming genomics data" 
author:
  - name: Stuart Lee
    email: stuart.lee1@monash.edu
    affiliation: Monash University
  - name: Michael Lawrence
    email: michael.lawrence@gene.com
    affiliation: Genentech
  - name: Di Cook
    email: di.cook@monash.edu
    affiliation: Monash University
address:
  - code: Monash University
    address: Department of Econometrics and Business Statistics, Clayton, Victoria, Australia
  - code: Genentech
    address: Bioinformatics and Computational Biology, Genentech, Inc., South San Francisco, California, United States of America 
abstract: |
    The Bioconductor project has created many useful data abstractions for analysing high-throughput genomics experiments. However, there is a cognitive load placed on a user in learning a data abstraction and understanding its appropriate use. Throughout a standard workflow, a user must navigate and know many of these abstractions to perform an genomic analysis task, when a single data abstraction, a GRanges object will suffice. The GRanges class naturally represent genomic intervals and their associated measurements. By recognising that the GRanges class follows 'tidy' data principles we have created a grammar of genomic data transformation. The grammar defines verbs for performing actions on and between genomic interval data. It provides a principled way
    of performing common genomic data analysis tasks through a coherent interface to existing Bioconductor infrastructure, resulting in human readable analysis workflows. We have implemented this grammar as a Bioconductor/R package called plyranges.
  
bibliography: references.bib
output: 
  rticles::plos_article:
csl: plos.csl
---
```{r setup, include = FALSE}
library(tibble)
library(knitr)
opts_chunk$set(message = FALSE, 
               warning = FALSE, 
               comment = "#>", 
               fig.width = 5, 
               fig.height = 3, 
               fig.align = "center")
# for peak figures
library(ggbio)
library(plyranges)

# -- Data from the Human Epigenomics RoadMap consortium
# retrieving a BigWigFile from AnnotationHub

if (!dir.exists("./data")) dir.create("./data")

library(AnnotationHub)
q <- AnnotationHub()
# T-cell BW file
bw_file <- q[["AH33458"]] 

# a BamFile from the H1 cell line
h1_bam <- "./data/GSM433167_BI.H3K27me3.bam"
if (!file.exists(h1_bam))
  download.file(
    url = "ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM433nnn/GSM433167/suppl/GSM433167%5FBI%2EH3K27me3%2Ebam",
    destfile = h1_bam
  )

h1_bam_sorted <- "./data/GSM433167_BI.H3K27me3.sorted.bam"

# sort and index bam
if (!file.exists(h1_bam_sorted)) {
  Rsamtools::sortBam(h1_bam, "./data/GSM433167_BI.H3K27me3.sorted")
  Rsamtools::indexBam(h1_bam_sorted)
}

# array data for h1 cell line
# illumina annotations
array_info <- "data/GPL18952_HumanOmni25M-8v1-1_B.annotated.txt.gz"
if (!file.exists(array_info)) 
  download.file(
    url = "https://www.ncbi.nlm.nih.gov/geo/download/?acc=GPL18952&format=file&file=GPL18952%5FHumanOmni2%2D5%2D8%2Dv1%2D1%2DC%2Ecsv%2Egz",
    destfile = array_info
  )

snp_info <- "data/GSM1463263_JS-ESCH1.txt.gz"
if (!file.exists(snp_info))
  download.file(
    url = "https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM1463263&format=file&file=GSM1463263%5FJS%2DESCH1%2Etxt%2Egz",
    destfile = snp_info
  )


```
# Introduction

High-throughput genomics promises to unlock new disease therapies,
and strengthen our knowledge of basic biology. To deliver on those promises, 
scientists must derive a stream of knowledge from a deluge of data. Genomic 
data is challenging in both scale and complexity. Innovations in sequencing 
technology often outstrip our capacity to process the output. Beyond their common
association with genomic coordinates, genomic data are heterogeneous,
consisting of raw sequence read alignments, genomic feature
annotations like genes and exons, and summaries like coverage vectors,
ChIP-seq peak calls, variant calls, and per-feature read
counts. Genomic scientists need software tools to wrangle the
different types of data, process the data at scale, test hypotheses,
and generate new ones, all while focusing on the biology, not the
computation. For the tool developer, the challenge is to define ways
to model and operate on the data that align with the mental model of
scientists, and to provide an implementation that scales with their
ambition.

Several domain specific languages (DSLs) enable scientists to process and reason
about heterogeneous genomics data by expressing common
operations, such as range manipulation and overlap-based joins, using
the vocabulary of genomics. Their implementations either delegate
computations to a database, or operate over collections of files in
standard formats like BED. An example of the former is the Genome Query 
Language (GQL) and its distributed implementation GenAp which use an 
SQL-like syntax for fast retrieval of information of unprocessed 
sequencing data @Kozanitis2014-va; @Kozanitis2016-bm. Similarly, the Genometric 
Query Language (GMQL) implements a relational algebra for combining genomic datasets 
@Kaitoua2017-pw.  The command line application BEDtools develops an extensive 
algebra for performing arithmetic between two or more sets of genomic regions 
@Quinlan2010-gc. All of the aforementioned DSLs are designed to be evaluated
either at the command line or embedded in scripts for batch processing. They 
exist in a sparse ecosystem, mostly consisting of UNIX and database tools that
lack biological semantics and operate at the level of files and
database tables.

The Bioconductor/R packages `IRanges` and `GenomicRanges` 
[@r-core; @Lawrence2013-wg; @Huber2015-ei] define a DSL for 
analysing genomics data with R, an interactive data analysis environment that 
encourages reproducibility and provides high-level abstractions for manipulating,
modelling and plotting data, through state of the art methods in
statistical computing. The packages define object-oriented (OO)
abstractions for representing genomic data and enable
interoperability by allowing users and developers to use these
abstractions in their own code and packages. Other genomic DSLs 
that are embedded in programming languages include pybedtools and valr 
[@Dale2011-js; @Kent2017], however these packages lack the interoperability
provided by the aforementioned Bioconductor packages and are not easily 
extended.

The Bioconductor infrastructure models the genomic data and operations from the
perspective of the power user, one who understands and wants to take
advantage of the subtle differences in data types. This design has
enabled the development of sophisticated tools, as evidenced by the
hundreds of packages depending on the framework. Unfortunately, the
myriad of data structures have overlapping purposes and important but
obscure differences in behavior that often confuse the typical end
user.

Recently, there has been a concerted, community effort to standardize
R data structures and workflows around the notion of tidy data
@Wickham2014-jc. A tidy dataset is defined as a tabular
data structure that has observations as rows and columns as variables,
and all measurements pertain to a single observational unit.
The tidy data pattern is useful because it allows 
us to see how the data relate to the design of an experiment
and the variables measured. The `dplyr` package [@Wickham2017-dplyr] 
defines an API that maps notions from the general relational algebra to 
operations on tidy data. It expresses each operation as a cohesive, endomorphic
verb. Taken together these features enable a user to write human
readable analysis workflows.

We have created a genomic DSL called `plyranges` that reformulates
notions from existing genomic algebras and embeds them in R as a
genomic extension of `dplyr`. By analogy, `plyranges` is to the
genomic algebra, as `dplyr` is to the relational algebra.  The
`plyranges` Bioconductor package implements the language on top of a
key subset of Bioconductor data structures and thus fully integrates
with the Bioconductor framework, gaining access to its scalable data
representations and sophisticated statistical methods.

# Genomic relational algebra

## Data model

\begin{figure}
{\centering \includegraphics[width=400pt]{diagrams/GRanges}}
\caption{An illustration of the GRanges data model for a
sample from an RNA-seq experiment. The core components of the data model
inlcude a seqname column (representing the chromosome), a ranges column
which consists of start and end coordinates for a genomic region, and a
strand identifier (either positive, negative, or unstranded). Metadata
are included as columns to the right of the dotted line as annotations
(gene\_id) or range level covariates (GC score and count).}
\label{fig:GRanges} 
\end{figure}

The `plyranges` DSL is built on the core Bioconductor data structure
GRanges, which is essentially a constrained table, with fixed columns
for the chromosome, start and end coordinates, and the strand, along
with an arbitrary set of additional columns, consisting of
measurements or metadata specific to the data type or experiment
(figure \ref{fig:GRanges}).  GRanges balances flexibility with formal
constraints, so that it is applicable to virtually any genomic
workflow, while also being semantically rich enough to support
high-level operations on genomic ranges. As a core data structure,
GRanges enables interoperability between plyranges and the rest of
Bioconductor. Adhering to a single data structure simplifies the API
and makes it easier to learn and understand, in part because
operations become endomorphic, i.e., they return the same type as
their input.

GRanges follows the intuitive tidy data pattern: it is a rectangular
table corresponding to a single biological context. Each row contains
a single observation and each column is a variable describing the
observations.  GRanges specializes the tidy pattern in that the
observations always pertain to some genomic feature, but it largely
remains compatible with the general relational operations defined by
dplyr. Thus, we define our algebra as an extension of the dplyr
algebra, and borrow its syntax conventions and design principles.

\begin{table}[!htbp]
\centering
\begin{tabular}{|l|l|p{4cm}|}
  \hline
  & Verb &  Description \\ 
  \hline
   & \textbf{\emph{summarise()}} & aggregate over column(s) \\ 
   Aggregation & \emph{disjoin\_ranges()} & aggregate column(s) over the union of end coordinates \\
   &  \emph{reduce\_ranges()} & aggregate column(s) by merging overlapping and neighbouring ranges \\
   \hline
   &  \textbf{\emph{mutate()}} & modifies any column \\
   & \textbf{\emph{select()}} & select columns \\
  Arithmetic (Unary) & \textbf{\emph{arrange()}} & sort by columns \\
   & \emph{stretch()} & extend range by fixed amount \\
   &  \emph{shift\_(direction)} & shift coordinates \\
   & \emph{flank\_(direction)} & generate flanking regions \\
   & \emph{\%intersection\% } & row-wise intersection \\
   & \emph{\%union\%} & row-wise union \\
   & \emph{compute\_coverage} & coverage over all ranges \\
  Arithmetic (Binary) &  \emph{\%setdiff\%} & row-wise set difference \\
   & \emph{between()} & row-wise gap range \\
   & \emph{span()} & row-wise spanning range \\
   \hline
    & \emph{join\_overlap\_*()} & merge by overlapping ranges \\
    & \emph{join\_nearest} & merge by nearest neighbour ranges \\
    & \emph{join\_follow} & merge by following ranges \\
    Merging & \emph{join\_precedes} & merge by preceding ranges \\
    & \emph{union\_ranges} & range-wise union \\
    & \emph{intersect\_ranges} & range-wise intersect \\
    & \emph{setdiff\_ranges} & range-wise set difference \\
    & \emph{complement\_ranges} & range-wise union \\
  \hline
   & \textbf{\emph{anchor\_direction()}} & fix coordinates at direction \\
  Modifier & \textbf{\emph{group\_by()}} & partition by column(s)  \\ 
   & \emph{group\_by\_overlaps()} & partition by overlaps \\
   \hline
   & \textbf{\emph{filter()}} & subset rows \\
  Restriction & \emph{filter\_by\_overlaps()} & subset by overlap \\
    & \emph{filter\_by\_non\_overlaps()} & subset by no overlap \\
   \hline
\end{tabular}
\caption{Overview of the \texttt{plyranges} grammar. The core verbs are
briefly described and categorised into one of: aggregation, unary or binary
arithmetic, merging, modifier, or restriction. A verb is given bold text if
its origin is from the \texttt{dplyr} grammar.}\label{tab:grammar}
\end{table}

## Algebraic operations

The `plyranges` DSL defines an expressive algebra for performing
genomic operations with and between GRanges objects (see table
\ref{tab:grammar}). The grammar includes several classes of operation
that cover most use cases in genomics data analysis. There are
range arithmetic operators, such as for resizing ranges or finding their
intersection, and operators for merging, filtering and aggregating by
range-specific notions like overlap and proximity.

Arithmetic operations transform range coordinates, as defined by their
_start_, _end_ and _width_. The three dimensions are mutually
dependent and partially redundant, so direct manipulation of them is
problematic. For example, changing the _width_ column needs to change
either the _start_, _end_ or both to preserve integrity of the
object. We introduce the _anchor_ modifier to disambiguate these
adjustments. Supported anchor points include the start, end and
midpoint, as well as the 3' and 5' ends for strand-directed
ranges. For example, if we anchor the start, then setting the width
will adjust the end while leaving the start stationary.

The algebra also defines conveniences for relative coordinate
adjustments: _shift_ (unanchored adjustment to both start and end) and
_stretch_ (anchored adjustment of width). We can perform any relative
adjustment by some combination of those two operations.  The _stretch_
operation requires an anchor and assumes the midpoint by
default. Since _shift_ is unanchored, the user specifies a suffix for
indicating the direction: left/right or, for stranded features,
upstream/downstream. For example, _shift\_right_ shifts a range to the
right.

The _flank_ operation generates new ranges that are adjacent to
existing ones. This is useful, for example, when generating upstream
promoter regions for genes. Analogous to _shift_, a suffix indicates
the side of the input range to flank.

As with other genomic grammars, we define set operations that treat
ranges as sets of integers, including _intersect_, _union_,
_difference_, and _complement_. There are two sets of these: parallel
and merging. The parallel operations map to infix operators, which we
surround with _%_ symbols, a convention borrowed from R syntax.  For
example, the parallel intersection (_x %intersect% y_) finds the
intersecting range between _xi_ and _yi_ for _i_ in _1...n_, where _n_
is the length of both _x_ and _y_. In constrast, the merging
intersection (_intersect\_ranges(x, y)_) returns a new set of disjoint
ranges representing whereever there was overlap between a range in _x_
and a range in _y_. We use the infix syntax for the parallel
operations, since it is the conventional syntax for parallel, binary
operations in R. Finding the parallel union will fail when two ranges
have a gap, so we introduce a _span_ operator that takes the union
while filling any gap. The _complement_ operation is unique in that it
is unary. It finds the regions not covered by any of the ranges in a
single set. Closely related is the _between_ parallel operation, which
finds the gap separating _xi_ and _yi_. The binary operations are
callable from within arithmetic, restriction and aggregation
expressions.

To support merging, our algebra recasts finding overlaps or 
nearest neighbours between two
genomic regions as variants of the relational join operator. A join
acts on two GRanges objects, a query and a subject. The join operator
is relational in the sense that metadata from the query and subject
ranges is retained in the joined range.  All join operators in the
`plyranges` DSL generate a set of hits based on overlap or proximity
of ranges and use those hits to merge the two datasets in different
ways. There are four supported matching algorithms: _overlap_,
_nearest_, _precede_, and _follow_ (figures 
\ref{fig:olaps-fig} and \ref{fig:nn-fig}). We can further restrict the
matching by whether the query is completely _within_ the subject, and
adding the _directed_ suffix ensures that matching ranges have the
same direction (strand).

```{r olaps-fig, echo = FALSE, out.width="400pt", fig.cap="Illustration of the three overlap join operators. Each join takes query and subject range as input (black and light gray rectangles, respectively). An index for the join is computed, returning a Hits object, which contains the indices of where the subject overlaps the query range. This index is used to expand the query ranges by where it was 'hit' by the subject ranges. The join semantics alter what is returned: for an \textbf{inner} join the query range is returned for each match, for an \textbf{intersect} the intersection is taken between overlapping ranges, and for a \textbf{left} join all query ranges are returned even if the subject range does not overlap them. This principle is gnerally applied through the `plyranges` DSL for both overlaps and nearest neighbour operations."}
knitr::include_graphics("diagrams/diagrams-002.png")
```

For merging based on the hits, we have three modes: _inner_,
_intersect_ and _left_. The _inner_ overlap join is similar to the
conventional inner join in that there is a row in the result for every
match. A major difference is that the matching is not by identity, so
we have to choose one of the ranges from each pair. We always choose
the left range. The _intersect_ join uses the intersection instead of
the left range. Finally, the overlap _left_ join is akin to left outer
join in Cobb's relational algebra: it performs an overlap inner join
but also returns all query ranges that are not hit by the subject.

```{r nn-fig, echo = FALSE, out.width = "400pt", fig.cap="Illustration of neighbour finding joins. Each join takes a query and subject range and computes a 'Hits' object. For the \textbf{nearest} join all query ranges are returned as they are all nearest neighbours of the second subject range. For the \textbf{follow} join there is only one query range that follows any subject range. Likewise for the \textbf{precede} join, there is only one query range that precedes a subject range."}
knitr::include_graphics("diagrams/diagrams-003.png")
```

Since the GRanges object is a tabular data structure, our grammar includes
operators to filter, sort and aggregate by columns in a GRanges. These 
operations can be performed over partitions formed
using the *group_by* modifier. Together with our algebra for arithmetic and
merging, these operations conform to the semantics and syntax of the 
`dplyr` grammar.

## Design principles

The design of plyranges adheres to well understood principles of
language and API design: cognitive consistency, cohesion,
expressiveness and endomorphism [cite: Green's cognitive
dimensions]. To varying degrees, these principles also underly the
design of dplyr and the Bioconductor infrastructure.

### Cognitive consistency and fluency

We aim for our interfaces to have a simple and direct mapping to the
user's cognitive model, i.e., how the user thinks about the data. This
requires careful selection of the level of abstraction so that the
user can express workflows in the language of genomics. This motivates
the adoption of the tidy GRanges object as our central data
structure. The basic data.frame and dplyr tibble lack any notion of
genomic ranges and so could not easily support our genomic grammar,
with its specific verbs for range-oriented data manipulation. Another
example of cognitive consistency is how plyranges is insensitive to
direction/strand by default when, e.g., detecting
overlaps. GenomicRanges has the opposite behavior. We believe that
defaulting to purely spatial overlap is most intuitive to most users.

<!--
ML:
Hadley actually presents dplyr as a 'cognitive tool', i.e., something
that helps users think about the problem. In my opinion, the best we
can do is attempt to match the intuition of the user, so when the user
decides what to do, there is an obvious way of doing it. I'm not ready
to claim that the user should start from our grammar.
-->

Like dplyr, plyranges verbs are functional: they are free of side
effects and return their result. This enables chaining of verbs
through syntax like the forward pipe operator (`%>%`, read as "then")
of the magrittr package @R-magrittr. This has syntax has a direct
cognitive mapping to natural language and the intuitive notion of
pipelines. The low-level object-oriented APIs of Bioconductor tend to
manipulate data via subreplacement functions, like `start(gr) <-
x`. These ultimately produce the side effect of replacing a symbol
mapping in the current environment and thus are not amenable to
so-called fluent syntax.

### Cohesion

A function is cohesive if it performs a singular task without
producing any side-effects. Singular tasks are not necessarily atomic;
they can always be broken down further at lower levels of abstraction.
For example, to resize a range, the user needs to specify which
position (start, end, midpoint) should be invariant over the
transformation. The `resize()` function from the GenomicRanges package
has a `fix` argument that sets the anchor, so calling `resize()`
coalesces anchoring and width modification. The coupling at the
function call level is justified since the effect of setting the width
depends on the anchor. However, plyranges increases cohesion and
decouples the anchoring into its own function call. 

Increasing cohesion simplifies the interface to each operation, makes
the meaning of arguments more intuitive, and relies on function names
as the primary means of expression, instead of a more complex mixture
of function and argument names. Since functions are superordinate to
their arguments, flattening the API at the function level enables the
user to conceptualize the API as a catalog of functions, without
having to descend further. A flat function catalog also enhances API
discoverability, particularly through auto-completion in IDEs. One
downside of pushing cohesion to this extreme is that function calls
become coupled, and care is necessary to treat them as a group when
modifying code.

### Expressiveness

Expressiveness relates to the information content in code: the
programmer should be able to clarify intent without unnecessary
verbosity. For example, our overlap-based join operations are more
concise than the multiple steps necessary to achieve the same effect
in the original GenomicRanges API. In other cases, the plyranges API
increases verbosity for the sake of clarity and cohesion. Explicitly
calling `anchor()` can require more typing, but the code is easier to
comprehend. Another example is the set of routines for importing
genomic annotations, including `read\_gff()`, `read\_bed()`, and
`read_bam()`. Compared to the generic `import()` in rtracklayer, the
explicit format-based naming in plyranges clarifies intent and the
type of data being returned. Similarly, every plyranges function that
computes with strand information indicates its intentions by including
suffixes such as `directed`, `upstream` or `downstream` in its name,
otherwise strand is ignored. The GenomicRanges API does not make this
distinction explicit in its function naming, instead relying on a
parameter that defaults to strand sensitivity, an arguably unintuitive
behavior.

# Results 

Here we provide illustrative examples by using the `plyranges` DSL to show
how our grammar could be integrated into genomic data workflows. We also
highlight how interoperability with existing Bioconductor infrastructure, 
enables easy access to public datasets and methods for analysis and 
visualisation.

## Peak Finding

The Bioconductor package `AnnotationHub` @R-ahub  can be used to search for 
BigWig files from ChIP-Seq experiments from the Human Epigenome Roadmap project 
@Roadmap_Epigenomics_Consortium2015-pr. Here we focus on assays for primary
T CD8+ memory cells from peripheral blood. Using `plyranges` we will read the 
BigWig file  corresponding to the H3 lysine 27 trimethylation (H3K27Me3) 
methylation mark over chromosome 10. 

First, we gather the BigWig file and extract its annotation information and 
filter it to chromosome 10.

[ML: please explain why we are doing this. Something like: we need to
     get the range for chromosome 10, so that we can use it as a
     filter when reading. The first time I read this, I was not sure what
     'annotation information' and 'gather' meant here. Why say
     "annotation information" when the API uses "genome information"?]

```{r load-bw, cache = TRUE}
library(plyranges)
chr10_ranges <- bw_file %>% 
  get_genome_info() %>%
  filter(seqnames == "chr10")
```

Then we read the BigWig file only extracting scores if they overlap chromosome
10. The annotation information from the file is automatically included (in this
case the hg19 genome build).

[ML: getting the genome info does not look automatic, because we are calling
	`set_genome_info()`; is that supposed to be here?]
	
```{r}
chr10_scores <- bw_file %>%
  read_bigwig(overlap_ranges = chr10_ranges) %>%
  set_genome_info(genome = "hg19")
```

The `reduce_ranges()` operation is used to find coverage peaks 
across chromosome 10. We can manually set a threshold to restrict genomic
regions to have a coverage score of greater than 8, and
then merge nearby regions. The maximum coverage is computed over all the
coverage scores in the regions that were reduced. 

[ML: I think the above text could do a better job of describing what
	`reduce_ranges()` does generally. You could say something like, after
	filtering for regions with a score greater than 8, we can reduce the
	individual runs to ranges representing the islands of coverage.]

```{r}
all_peaks <- chr10_scores %>% 
  filter(score > 8) %>% 
  reduce_ranges(score = max(score))
```

Returning to the GRanges object containing normalised coverage scores, 
we filter to find the coordinates of the peak 
containing the maximum coverage score. We can then find 
a 5000 nt region centered around the maximum position by anchoring and 
modifying the the width. 

```{r max-score-region}
chr10_max_score_region <- chr10_scores %>%
  filter(score == max(score)) %>% 
  anchor_center() %>%
  mutate(width = 5000)
```

Finally, the overlap inner join is used to restrict the chromosome 10
normalised coverage scores that are within the 5000nt region that contain
the max peak on chromosome 10 (figure \ref{fig:peak-viz}).

```{r peak_region}
peak_region <- chr10_scores %>%
  join_overlap_inner(chr10_max_score_region)

```

```{r peak-viz, echo = FALSE, fig.cap = "Visualisation of normalised coverage scores accross a 5000nt region of chromosome 10 from H3K27Me3 ChIP-Seq assay from the Human Epigenome Roadmap project."}
ggbio::autoplot(peak_region, 
                aes(y = score.x), 
                geom = "blank") + 
  geom_area(aes(x = start))
```


## Computing Windowed Statistics

Another common operation in genomics data analysis is to compute data
summaries over genomic windows. In `plyranges` this can be achieved via
the `group_by_overlaps` operator. Continuing with the data from the 
Human Epigenome Roadmap Consortium data, we can count the number of reads
that fall into a fixed bins of size 10000bp over a sorted and indexed 
BAM file of H3K27Me3 methylation marks from the H1 cell line. 

We can resuse the annotation information from our BigWig file example, as the
BAM file was aligned to the hg19 genome build. Alignments over
the mitochondrial genome are dropped using the `dropSeqlevels` function
from the Bioconductor package `GenomeInfoDb` @R-gdb.
```{r locations, eval = FALSE}
locations <- bw_file %>%
  get_genome_info() %>% 
  dropSeqlevels("chrM", pruning.mode = "coarse") %>%
  set_genome_info(genome = "hg19") 
```

To generate bins of width 10000bp we can use the `tile` function from 
`GenomicRanges`:

```{r, eval = FALSE}
bins <- tile(locations, width = 10000)
```

Next we only read in alignments if they have a map quality score
greater than 20.
```{r, eval = FALSE}
alignments <- read_bam(h1_bam_sorted) %>%
    filter(mapq > 20) 
```

Finally, we can use `group_by_overlaps` with `summarise` to compute the
total number of reads within each window.

```{r, eval = FALSE}
alignments_summary <- bins %>%
  group_by_overlaps(alginments) %>%
  summarise(n_reads = n())
```

<!-- 
https://support.bioconductor.org/p/71601/ also useful example?
-->

## Quality Control Metrics

```{r, echo = FALSE, warning = FALSE, cache = TRUE}
# prepare a GRanges object from array data
library(readr)
# annotation information available here
# https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GPL18952
# chromosome zero are 'problem' probes and should be filtered
anno <- read_tsv(array_info,
                 trim_ws = TRUE,
                 col_types = c("cccc----")) %>%
  dplyr::filter(Chr != "0")

# genotypes for H1 cell line, data starts on line 10
# data obtained from https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM1463263
geno <- read_tsv(snp_info, skip = 10) 

# rename columns
geno <- geno %>% 
  dplyr::select(name = `SNP Name`, 
         score = `GC Score`, 
         baf = `B Allele Freq`, 
         logR = `Log R Ratio`)

# merge everything
complete_vranges_df <- dplyr::inner_join(geno, anno, by = c("name" = "Name")) %>%
  dplyr::rename(alleles = Alleles, seqnames = Chr, start = MapInfo)

h1_snp_array <- as_granges(complete_vranges_df,
                           start = as.integer(start),
                           end = as.integer(start))
h1_snp_array <- h1_snp_array %>% 
  mutate(ref = stringr::str_replace(alleles, "\\[(.)/.*", "\\1"),
         alt = stringr::str_replace(alleles, ".*/(.)\\]", "\\1"))
```

We have created a GRanges object from genotyping performed on the
H1 cell line, consisting of approximately two million single nucleotide
polymorphisms (SNP) and short insertion/deletions (indel). The GRanges object consists
of 7 columns, relating to the alleles of a SNP or indel, the B-allele frequency,
log relative intensity of the probes, GC content score over a probe, and the
name of the probe. We can use this information to compute the transition-transversion
ratio, a quality control metric, within each chromosome in GRanges object.

First we filter out any insertion or deletion alleles and 
the SNPs present on the mitochondria then create a logical vector corresponding
to whether there is a transition event. 

```{r}
h1_snp_array <- h1_snp_array %>%
  filter(!(ref %in% c("I", "D")), seqnames != "M") %>%
  mutate(transition = (ref %in% c("A", "G") & alt %in% c("G","A")) |
                      (ref %in% c("C","T") & alt %in% c("T", "C")))
```

We can then compute the transition-transversion ratio using the `group_by`
and `summarise` pattern, it is computed as the total number of transition
SNPs divided by the total number of transversion SNPs within each chromosome
(figure \ref{fig:titv-viz}).

```{r}
ti_tv_results <- h1_snp_array %>% 
  group_by(seqnames) %>%
  summarise(n_snps = n(),
            ti_tv = sum(transition) / sum(!transition)) 
```

```{r titv-viz, echo = FALSE, fig.cap = "Dot plot of chromosomes ordered by estimated transition-transversion ratio. A white reference line is drawn at the expected ratio for a human exome."}
ti_tv_results %>% 
  as.data.frame() %>% 
  ggplot(aes(forcats::fct_reorder(seqnames, ti_tv), ti_tv)) +
  geom_point() + 
  geom_hline(yintercept = 3, colour = "white", size = 4) +
  labs(x = "Chromosome", y = "Transition Transverion Ratio") +
  coord_flip() 
```

<!-- 
Trivial example? Could do something with a smooth summarised over
genomic coordinates? 
-->


# Discussion 

A caveat to constructing a compatible interface with `dplyr` is that 
`plyranges` makes extensive use of non-standard evaluation in R
(achieved via the `rlang` package @R-rlang). Simply, this
means that computations are performed and evaluated in the context of the 
GRanges objects; emphasising the interactive nature of our API.
Consequently, when programming with `plyranges` a user needs to be aware of
how non-standard evaluation in R works and how to adapt their code 
accordingly. However, with the rise of R packages like `rlang` this process
is becoming less difficult.

While GRanges are an intuitive representation for data measured on genomic regions,
more flexible data structures are required to represent data from multiple sample
experiments. The Bionconductor class SummarizedExperiment is the canonical 
data structure for representing data for combining multiomic measurements 
from multiple samples. The grammar and design of the `plryanges` DSL can be
naturally extended to the SummarizedExperiment. 


# Availablilty and Future Work

The `plyranges` package is available on the Bioconductor project website 
[https://bioconductor.org](https://bioconductor.org) or can be accessed
via Github [https://github.com/sa-lee/plyranges](https://github.com/sa-lee/plyranges).
We aim to continue developing the `plyranges` package and extend it for use
with more complex data structures  such as the 
SummarizedExperiment class, which can be used for analysing transcriptomic
and variant data. As the `plyranges` interface encourages tidy data 
practices it integrates well with the principles of the grammar of graphics, 
we aim to use it to prepare data for the visualisation of multimodal biological 
datasets.

# Acknowledgements

We would like to thank Dr Matthew Ritchie at the Walter and Eliza Hall 
Institute and Dr Paul Harrison for their feedback on earlier drafts of
this work. We would also like to thank Lori Shepherd and HÃ¨rve Pages
for the code review they performed. This report was written with
`knitr` @R-knitr and the figures were made with `ggbio` @R-ggbio. All code
required to reproduce this article is available at 
https://github.com/sa-lee/plyranges-paper.

# References {#references .unnumbered}
