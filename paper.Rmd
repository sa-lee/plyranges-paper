---
title: "plyranges: a grammar for transforming genomics data" 
author:
  - name: Stuart Lee
    email: stuart.lee1@monash.edu
    affiliation: Monash University
  - name: Michael Lawrence
    email: michael.lawrence@gene.com
    affiliation: Genentech
  - name: Di Cook
    email: di.cook@monash.edu
    affiliation: Monash University
address:
  - code: Monash University
    address: Department of Econometrics and Business Statistics, Clayton, Victoria, Australia
  - code: Genentech
    address: Bioinformatics and Computational Biology, Genentech, Inc., South San Francisco, California, United States of America 
abstract: |
    The Bioconductor project has created many useful data abstractions for analysing high-throughput genomics experiments. However, there is a cognitive load placed on a user in learning a data abstraction and understanding its appropriate use. Throughout a standard workflow, a user must navigate and know many of these abstractions to perform an genomic analysis task, when a single data abstraction, a _Ranges_ object will suffice. The _Ranges_ class naturally represent genomic intervals and their associated measurements. By recognising that the _Ranges_ class follows 'tidy' data principles we have created a grammar of genomic data transformation. The grammar defines verbs for performing actions on and between genomic interval data. It provides a principled way
    of performing common genomic data analysis tasks through a coherent interface to existing Bioconductor infrastructure, resulting in human readable analysis workflows. We have implemented this grammar as an Bioconductor/R package called plyranges.
  
bibliography: references.bib
output: 
  rticles::plos_article:
csl: plos.csl
---
```{r setup, include = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, comment = "#>", 
                      fig.width = 5, fig.height = 3, fig.align = "center")
options(digits = 2)
library(ggbio)
library(ggplot2)
library(plyranges)

library(AnnotationHub)
q <- AnnotationHub()
bw_file <- q[["AH33458"]] 
```
# Introduction

There is a large variety of genomics data available to the scientific community,
ranging from highly specific sequencing assays to publicly availble collections.
These datasets similarly contain a wide variety of features: annotations of 
genomic features such as genes or exons for reference genomes, large coverage 
vectors, peaks called from ChIP-Seq experiments and many more. A modern biologist
is expected to be able to reason about, combine and wrangle these heterogenous
data sources in order to answer questions about their experimental hypotheses.
Abstractions in the forms of data representation and software interfaces are
key factors in inhibiting or enabling a biologist to construct reproducible data workflows
to answer their research questions. 

Many domain specific languages (DSLs) have been created to process and reason
about heterogenous genomics data. Broadly, they are implemented as either
query languages or as an embedded command line tool.
An example of the former is the Genome Query Language (GQL) and its distributed 
implementation GenAp which use an SQL-like syntax for fast retrieval of 
information of unprocessed sequencing data @Kozanitis2014-va; @Kozanitis2016-bm. 
Similarly, the Genometric Query Language (GMQL) implements a 
relational algebra for combining genomic datasets @Kaitoua2017-pw.  
The command line application BEDtools develops an extensive algebra for 
performing arithmetic between two or more sets of genomic regions 
@Quinlan2010-gc; @Dale2011-js. All of the aformentioned DSLs are designed to 
be run either at the command line or embedded in scripts for batch processing. 
As a consquence, they are not integrated into an environment designed to 
perform interactive data  analysis that has access to state of the art 
methods for statistics and visualisation like the R language. 

The Bioconductor/R packages `IRanges` and `GenomicRanges` 
define a DSL for analysing genomics data with R via
an object-oriented (OO) interface @Lawrence2013-wg; @Huber2015-ei. This interface
provides abstractions for representing genomics data and enables interoperability
by allowing users and developers to use these abstractions in their own code
and packages. However, due to the large number of abstractions there are costs
involved. Due to the OO interface each abstraction will behave slightly 
differently for any given generic method. There is a cognitive load on the user
to understand the appropriate context for each abstraction. An alternative approach
is to recognise that most genomic data analysis tasks can be performed with 
data structures that naturally represent genomic intervals. That is, genomics
data can be represented as sets of integer pairs, where each pair has a start
and an end coordianate, along with strings representing strand and chromosome 
location. Measurements or metadata can be included as additional annotations
on each pair.  As an example. a gene can be represented with its coordinates, along with its 
identifier and the identifiers of its exons; or an RNA-seq experiment may be
represented as sets of genes with a matching count column.


This natural abstraction aligns with the concept of tidy data @Wickham2014-jc. 
A tidy dataset is defined to be to a tabular
data structure that has observations as rows and columns as variables, and each
tidy dataset represents measurements from a single observational unit.
The tidy data pattern is useful because it allows 
us to see how the data relates to the design of an experiment
and the variables measured. The genomic interval data structure follows 
this pattern: it is a rectangular table corresponding to a single biological 
context. Each row contains a single observation and each column is a variable about
that observation. 

The tidy data abstraction enables the construction of fluent application programming interfaces (APIs) [@Fowler2010-zd] that are optimised for readability. An example of a 
fluent interface built on the tidy data pattern is the R pacakge `dplyr` [@Wickham2017-dplyr]. 
The package defines a consistent syntax and style for transforming tabular data sets via
functions that are named as verbs. Each function performs an action on the data
set and is cohesive and endomorphic. Cohesion means that each function performs
a singular task and has no side-effects, while endomorphism means a function
call returns the same type of object as its input. Taken together these
features enable a user to write human readable analysis workflows.

We have created a DSL called `plyranges` that is directly motivated by the design
of `dplyr` but extends its  grammar to incorporate features of genomics data.
Our interface uses the existing Bioconductor packages `IRanges` and 
`GenomicRanges` but simplifies them by only exposing tidy genomic interval
data structures to the user. Hence, we can encapsulate the features of the 
of the `dplyr` API while performing genomic specific transformations 
such as finding overlapping  regions or nearest neighbour regions between 
genomic intervals.  The `plyranges` DSL is designed to enable fast interactive 
analysis of genomics but also enables the creation of reproducible genomic 
data workflows.

# Design and Implementation

<--- need to formally introduce the Ranges classes now --->

We have designed the API to be fluent. Every function call corresponds to an
action on a _Ranges_ object (they are named verbs) and where possible
functions have few arguments. Each verb is constructed
to enable a tab completion based workflow. Both of these aspects reduce the 
cognitive load on a new user since most manipulations can be performed with a 
vocabulary of several verbs, rather than having to memorise functions with many 
arguments that are nouns (as is required in the existing Bioconductor packages). 
This is also has the advantage of allowing users to write human readable code
because verbs describe what the code is doing rather than how its doing it.

Workflows can be composed by chaining verbs together via the forward pipe operator,`%>%` 
(exported from the R package _magrittr_ @R-magrittr). This is possible because every 
function call is an endomorphism: when the input is _Ranges_ object the output
will also be a _Ranges_ object. One advantage of endomorphism is that it 
does not  require any additional learning of classes beyond _Ranges_ and 
the _DataFrame_ classes. This strongly deviates from the design of 
the _Ranges_ Bioconductor packages, where many methods return a new class
upon return. The Bioconductor design enables efficient computing as users
are exposed to low-level features of its API which _plyranges_ abstracts
away. Method chaining via the pipe operator can also be difficult to debug,
as there multiple points of failure.

In order to provide a compatible API with _dplyr_, _plyranges_ makes extensive 
use of non-standard evaluation in R via the _rlang_ package @R-rlang. Simply, this
means that computations are performed and evaluated in the context of the 
_Ranges_ objects, which emphasises the interactive nature of the API. This has
the disadvantage that programming with _plyranges_ becomes more difficult 
because a user needs to capture expressions inside function calls and then
unquote them.
<!--- need to make this clearer? --->

## Actions on Ranges 

The _plyranges_ API exports the six core verbs from the _dplyr_ package
and modifies them for use with _Ranges_ objects. The
verb `mutate()` takes a Ranges object and a set of name-value pairs
and generates a new Ranges object that with modified or new metadata
columns or modified core components (start, end, width, seqnames, strand).
The use of `mutate()` means that a user no longer needs knowledge of the 
accessors of the Ranges object, as they can modify them in place.
The `filter()` function takes a Ranges object and logical expressions and
restricts Ranges object to where the logical expression evaluates to true.
The `summarise()` function takes a Ranges object and a set of name-value pairs
and aggregates the Ranges according to functions evaluated in the name-value pairs.
As `summarise()` is an aggregation it may break the structure of the of a Ranges
object, hence it returns a _DataFrame_ object.
The `select()` function determines
which metadata columns are returned and the order they are returned in. The 
`arrange()` function sorts a Ranges object by named variables. 
The `group_by()` function creates an implicit grouping of Ranges object according
to variables in the Ranges object. This modifies the actions of `mutate()`,
`summarise()` and `filter()`, so they are performed on each partition created 
by the grouping. The `group_by()` operation acts as a replacement for 
the _GenomicRangesList_ class in the original _GenomicRanges_ API.

The _plyranges_ API introduces additional summary verbs, `reduce_ranges()`
and `disjoin_ranges()`that return Ranges objects after being returned. The
`reduce_ranges()` operation merges overlapping and neighbour ranges, while
`disjoin_ranges()` expands ranges by taking the union of end points. 

## Arithimetic on Ranges

The _plyranges_ API has an expressive algebra for performing arithmetic on Ranges via
the verbs `set_width()` and `stretch()`. As the names suggest `set_width()`
modifies the width of a Ranges object, while `stretch` extends the start and
end of a Ranges object. These can be chained with the anchoring functions
`anchor_start()`, `anchor_end()`, `anchor_center()`, `anchor_3p()` or 
`anchor_5p()`, which fix the coordinates of a Ranges object in place. 
Moreover, the `shift_` and `flank_` family of functions can be used to shift
all coordinates in a Ranges object or generate flanking regions from a Ranges 
object to the left, right, upstream or downstream of the input. Unlike, the
Bioconductor API, _plyranges_ makes it explicit via function calls whether to
take into account the strand information of a _Ranges_ object.

## Overlapping Ranges

A common operation to perform between two _Ranges_ objects is to find overlaps
or nearest neighbours. The _plyranges_ API recasts these operations as 'joins'
or 'pairing' operations. For overlaps, there are three join operations: 
`join_overlap_intersect()`, `join_overlap_inner()` and `join_overlap_left()`
which are shown in figure (\ref{fig:olap}). 

```{r olap, echo = FALSE, fig.cap="The three overlap joins: the query and subject ranges are coloured by their metadata. When an overlap is performed the resulting range is filled by the query metadata and the metadata from the subject colours the outside of the range.", fig.width = 5, fig.height = 7}
a <- GRanges(seqnames = "chr1",
               strand = c("+", "-"),
               ranges = IRanges(c(1, 9), c(7, 10)),
               key.a = letters[1:2])

b <- GRanges(seqnames = "chr1",
               strand = c("-", "+"),
               ranges = IRanges(c(2, 6), c(4, 8)),
               key.b = LETTERS[1:2])

c <- join_overlap_intersect(a,b)
d <- join_overlap_inner(a, b)
e <- join_overlap_left(a, b)

p1 <- autoplot(a, aes(fill = key.a)) + 
  scale_fill_brewer(type = "qual", palette = "Set2") + 
  guides(fill = FALSE)
p2 <- autoplot(b, aes(fill = key.b))  + 
  scale_fill_brewer(type = "qual", palette = "Set1") +
  guides(fill = FALSE)
p3 <- autoplot(c, aes(fill = key.a, colour = key.b)) + 
  scale_fill_brewer(type = "qual", palette = "Set2") +
  scale_color_brewer(type = "qual", palette = "Set1") +
  guides(fill = FALSE, color = FALSE) 
p4 <- autoplot(d, aes(fill = key.a, colour = key.b)) + 
  scale_fill_brewer(type = "qual", palette = "Set2") +
  scale_color_brewer(type = "qual", palette = "Set1") +
  guides(fill = FALSE, colour = FALSE)
p5 <- autoplot(e, aes(fill = key.a, colour = key.b))  +
  scale_fill_brewer(type = "qual", palette = "Set2") +
  scale_color_brewer(type = "qual", palette = "Set1") +
  guides(fill = FALSE, colour = FALSE)

tracks(query = p1, subject = p2, 
       `intersect` = p3, 
       `inner` = p4, 
       `left` = p5) 
```

These operations consider any overlap between
two input ranges and return any corresponding metadata from both Ranges objects
as metadata. The intersect join takes the intersect of the start and end coordinates
of overlapping intervals of the query and subject _Ranges_ 
(for _GenomicRanges_ it also accounts for sequence name), when there is a overlap
the metadata corresponding to the query and subject _Ranges_ are returned. 
Similarly, inner join takes the start and end coordinates of the query _Ranges_
that overlap the subject _Ranges_ and returns metadata of the overlapping query
and subject _Ranges_. Finally, the left join performs a left outer join between
the query and subject _Ranges_, it returns all genomic intervals from the query
ranges, and returns missing values in metadata columns when there is no overlap.

A user may also restrict or group by overlaps with the `filter_by_overlaps()`,
`filter_by_non_overlaps()` and `group_by_overlaps()`. All overlap methods can
be modified with the `within` suffix (which changes the type of overlap 
from 'any' to 'within') or the `directed` suffix (which takes into account
the strand of a _GenomicRanges_ object.). 

For nearest neighbours, the _plyranges_ API provides `join_nearest()`, 
`join_precede()`, and `join_follow()` functions. These functions are similar
to the overlapping functions, in that they return the query ranges that are
nearest (or precede or follow) the subject ranges and add metadata from
the subject ranges when the query is a nearest neighbour of the subject. Like
the overlap joins, these functions can modified with suffixes to find nearest
neighbours that are left, right, upstream or downstream of the subject.

The pairing operations, `pair_overlap()`, `pair_nearest()`, `pair_follow()`, 
and `pair_precede()` are similar to the join operation but instead of returning
a _Ranges_, they pair up the subject and query _Ranges_ objects into a _DataFrame_,
alongside their metadata columns. This data structure is similar to the _Pairs_
data structure in the _S4Vectors_ @R-S4vectors package or the BED-PE file format. 

The combination of verbs we have defined above encapsulate all operations that
can be performed in the original _IRanges_ and _GenomicRanges_ packages
without the user be exposed to new classes. In those packages to perform
most operations requires users to learn many classes and perform 
additional manipulations to return the results of their computation back to a
_Ranges_ object.

## Construction and Import/Output

The methods `as_granges()` and `as_iranges()`
for constructing _Ranges_ from tabular data structures, such as the _data.frame_ in
base R. These methods use non-standard evaluation so columns in a _data.frame_
can be modified before a _Ranges_ object is created. The API also has
convenience methods for annotating or extracting annotations from _GRanges_
objects with the `set_genome_info()` and `get_genome_info()` functions.

There is a consistent framework for reading and writing 
files from and to common genomic data formats, using the _rtracklayer_ package
as a back-end @Lawrence2009-nt. The methods are implemented in the `read_/write_` family of 
functions, currently _plyranges_ can read and write BAM, BED, BEDPE, 
narrowPeaks, GFF/GTF, WIG and BigWig files. 

# Results 

As an example, we use the Bioconductor package _AnnotationHub_ @R-ahub to search for 
BigWig files from ChIP-Seq experiments from the Human Epigenome Roadmap project @Roadmap_Epigenomics_Consortium2015-pr.
We choose to focus on assays for primary T CD8+ memory cells from peripheral 
blood. We can then read the BigWig file  corresponding to the H3 lysine 27 
 trimethylation (H3K27Me3) 
methylation mark over chromosome 10. 

First, we gather the BigWig file
and extract its annotation information and filter it to chromosome 10.

```{r load-bw, cache = TRUE}
library(plyranges)
chr10_ranges <- bw_file %>% 
  get_genome_info() %>%
  filter(seqnames == "chr10")
```

Then we read the BigWig file only extracting scores if they overlap chromosome
10. The annotation information from the file is automatically included (in this
case the hg19 genome build).

```{r}
chr10_scores <- bw_file %>%
  read_bigwig(overlap_ranges = chr10_ranges) %>%
  set_genome_info(genome = "hg19")
chr10_scores
```

The `reduce_ranges()` operation is used to find coverage peaks 
across chromosome 10. We can manually set a threshold to restrict genomic
regions to have a coverage score of greater than 8, and
then merge nearby regions. The maximum coverage is computed over all the
coverage scores in regions that were reduced. 

```{r}
all_peaks <- chr10_scores %>% 
  filter(score > 8) %>% 
  reduce_ranges(score = max(score))
```

Returning to the _Ranges_ object containing normalised coverage scores for
the methylation data, we can filter to find the coordinates of the peak 
containing maximum coverage score. We can then find 
a 5000 nt region centered around the maximum position by anchoring and 
modifying the the width. 

```{r max-score-region}
chr10_max_score_region <- chr10_scores %>%
  filter(score == max(score)) %>% 
  anchor_center() %>%
  set_width(5000)
```

Finally, the overlap inner join could be used to restrict the chromosome 10
normalised coverage scores that are within the 5000nt region that contains
the max peak on chromosome 10 (visualised in figure \ref{fig:peak-viz}).

```{r peak_region}
peak_region <- chr10_scores %>%
  join_overlap_inner(chr10_max_score_region %>% 
                       select(-score))

```

```{r peak-viz, echo = FALSE, fig.cap = "Visualisation of normalised coverage scores accross a 5000nt region of chromosome 10 from H3K27Me3 ChIP-Seq assay from the Human Epigenome Roadmap project."}
ggbio::autoplot(peak_region, 
                aes(y = score), 
                geom = "blank") + 
  geom_area(aes(x = start))
```


# Availablilty and Future Work

The _plyranges_ package is available on the Bioconductor project website 
[https://bioconductor.org](https://bioconductor.org) or can be accessed
via Github [https://github.com/sa-lee/plyranges](https://github.com/sa-lee/plyranges).
We aim to continue developing the _plyranges_ package and extend it for use
with more complex data structures  such as the 
_SummarizedExperiment_ class, which can be used for analysing transcriptomic
and variant data. As the _plyranges_ interface encourages tidy data 
practices it integrates well with the principles of the grammar of graphics, 
we aim to use it for the visualisation of multimodal biological datasets.

# References {#references .unnumbered}
